{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading, storage, and file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from numpy.random import randn\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(12345)\n",
    "plt.rc('figure', figsize=(10, 6))\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing Data in Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat ch06/ex1.csv    # \\ 으로 바꿔주기   # 첫줄은 데이터가 아님\n",
    "!type ch06\\ex1.csv                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ch06/ex1.csv')   # pandas  # 경로와 파일이름.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table('ch06/ex1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!type ch06\\ex2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('ch06/ex2.csv', header=None)\n",
    "pd.read_csv('ch06/ex2.csv', names=['a', 'b', 'c', 'd', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['a', 'b', 'c', 'd', 'message']\n",
    "pd.read_csv('ch06/ex2.csv', names=names, index_col='message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!type ch06\\csv_mindex.csv\n",
    "parsed = pd.read_csv('ch06/csv_mindex.csv', index_col=['key1', 'key2'])\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(open('ch06/ex3.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_table('ch06/ex3.txt', sep='\\s+')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!type ch06\\ex4.csv\n",
    "pd.read_csv('ch06/ex4.csv', skiprows=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!type ch06\\ex5.csv\n",
    "result = pd.read_csv('ch06/ex5.csv')\n",
    "result\n",
    "pd.isnull(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('ch06/ex5.csv', na_values=['NULL'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinels = {'message': ['foo', 'NA'], 'something': ['two']}\n",
    "pd.read_csv('ch06/ex5.csv', na_values=sentinels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading text files in pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!type ch06\\ex6.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = pd.read_csv('ch06/ex6.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('ch06/ex6.csv', nrows=5)     # 5개만~! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = pd.read_csv('ch06/ex6.csv', chunksize=1000)\n",
    "chunker      # pandas.io.parsers.TextFileReader 의 객체이다.   \n",
    "# chunker 덩어리 : 1000개씩/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = pd.read_csv('ch06/ex6.csv', chunksize=1000)\n",
    "                       # 굉장히 큰 파일 / 헤더 있고 / 10000개 있음     => 이것보다 크면 chunk 로 쪼개서 하면 나음\n",
    "tot = Series([])\n",
    "for piece in chunker:  # chunker 에서 한조각씩 빼서 \n",
    "    tot = tot.add(piece['key'].value_counts(), fill_value=0)\n",
    "    # 부분 부분 더해주고    # 칼럼명 key                   b가 몇개 / L이 몇개\n",
    "    \n",
    "tot = tot.sort_values(ascending=False)            # 그 부분부분을 정렬해줌 내림차순"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tot[:10]    # 10000건 중에서  상위 10건\n",
    "tot[-10:]     # 끝에서 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 지금까지는 읽어오는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data out to text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ch06/ex5.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('ch06/out.csv')        # 파일 새로 만들기\n",
    "!type ch06\\out.csv                # 헤더가 출력되고, 인덱스도 출력됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(sys.stdout, sep='|')   # 출력할 파일의 경로와 조건을 넣어줌\n",
    "            #출력대상이 표준출력으로 되어있음            # 수직 바로 구분 seperate\n",
    "            # standard bar       \n",
    "        # 중간에 null 값도 있음. => null 값이 잘 안보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(sys.stdout, na_rep='NULL')\n",
    "                        # null representitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(sys.stdout, index=False, header=False) # 인덱스, 헤더 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(sys.stdout, index=False, columns=['a', 'b', 'c'])\n",
    "                                     # a,b,c 까지만 보여주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('1/1/2000', periods=7)       # 7개의 데이터를 보여주세요.\n",
    "dates          # 시간의 범위  주가, 농산물 가격, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = Series(np.arange(7), index=dates)   # 인덱스에 dates 자료를 넣어주면\n",
    "ts    # 시리즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.to_csv('ch06/tseries.csv')\n",
    "!type ch06\\tseries.csv             # 자료를 csv로 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!type ch06\\tseries.csv\n",
    "st1 = Series.from_csv('ch06/tseries.csv', parse_dates=True)            \n",
    "                  # 시리즈로 만드는데, 2000-01-01을 날짜형로 perse 해주세요.                          \n",
    "st1\n",
    "st1.index                                                        # 날짜 데이터\n",
    "st2 = Series.from_csv('ch06/tseries.csv', parse_dates=False)       \n",
    "st2\n",
    "st2.index                                                       # 그냥 문자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually working with delimited formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!type ch06\\ex7.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open('ch06/ex7.csv')\n",
    "\n",
    "reader = csv.reader(f)\n",
    "reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in reader:\n",
    "    print(line)         # 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = list(csv.reader(open('ch06/ex7.csv')))    # 반복 문 대신에 처리함.\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, values = lines[0], lines[1:]      # line의 0 첫번째 항목 = 헤더에 넣고, line의 나머지 항목 = values에 넣음\n",
    "header\n",
    "values                       # zip 헤더에서  a를 하나 갖고 오고, values에서 풀어짐.             #\n",
    "data_dict = {h: v for h, v in zip(header, zip(*values))}    # zip([1,2],[3,4],[5,6])   => 1 3 5 / 2 4 6\n",
    "                                       # zip *values 중첩리스트가 풀리고 zip([1,2,3],[1,2,3,4]) => 11 22 33 x / 짧은 걸로 반환됨.             \n",
    "data_dict      # 판다스는 아무것도 안씀."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dict = {'start' : 3, 'end': 10, 'step': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dialect(csv.Dialect):  # 상위클래스가 됨\n",
    "    lineterminator = '\\n'       # 줄바꿈 문자\n",
    "    delimiter = ';'           #\n",
    "    quotechar = '\"'          #\n",
    "    quoting = csv.QUOTE_MINIMAL   # 변수값을 가져다 쓰겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mydata.csv', 'w') as f:  \n",
    "    writer = csv.writer(f, dialect=my_dialect)    # 구분자\n",
    "    writer.writerow(('one', 'two', 'three'))\n",
    "    writer.writerow(('1', '2', '3'))\n",
    "    writer.writerow(('4', '5', '6'))\n",
    "    writer.writerow(('7', '8', '9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat mydata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    " \"places_lived\": [\"United States\", \"Spain\", \"Germany\"], \n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 25, \"pet\": \"Zuko\"},\n",
    "              {\"name\": \"Katie\", \"age\": 33, \"pet\": \"Cisco\"}]\n",
    "}\n",
    "\"\"\" \n",
    "# 여러개니까 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "result = json.loads(obj)        # 파이썬의 사전으로 변환하는 것\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asjson = json.dumps(result)     # 파이썬의 사전을 json 으로 변환하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siblings = DataFrame(result['siblings'], columns=['name', 'age'])\n",
    "siblings\n",
    "siblings.to_json()       # pandas가 제공해주는 것\n",
    "# 인덱스 / name / age   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML and HTML, Web scraping\n",
    "\n",
    "**NB. The Yahoo! Finance API has changed and this example no longer works**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.html import parse\n",
    "from urllib.request import urlopen\n",
    "\n",
    "parsed = parse(urlopen('https://finance.yahoo.com/q/op?s=AAPL+Options'))\n",
    "\n",
    "doc = parsed.getroot()\n",
    "\n",
    "# SSL 에러뜸 : 보안을 강화시키는 것, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = doc.findall('.//a')\n",
    "links[15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnk = links[28]\n",
    "lnk\n",
    "lnk.get('href')\n",
    "lnk.text_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [lnk.get('href') for lnk in doc.findall('.//a')]\n",
    "urls[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = doc.findall('.//table')\n",
    "calls = tables[9]\n",
    "puts = tables[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = calls.findall('.//tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _unpack(row, kind='td'):\n",
    "    elts = row.findall('.//%s' % kind)\n",
    "    return [val.text_content() for val in elts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_unpack(rows[0], kind='th')\n",
    "_unpack(rows[1], kind='td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.parsers import TextParser\n",
    "\n",
    "def parse_options_data(table):\n",
    "    rows = table.findall('.//tr')\n",
    "    header = _unpack(rows[0], kind='th')\n",
    "    data = [_unpack(r) for r in rows[1:]]\n",
    "    return TextParser(data, names=header).get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_data = parse_options_data(calls)\n",
    "put_data = parse_options_data(puts)\n",
    "call_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing XML with lxml.objectify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ch06/mta_perf/Performance_XML_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -21 Performance_MNR.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify\n",
    "\n",
    "path = 'Performance_MNR.xml'\n",
    "parsed = objectify.parse(open(path))\n",
    "root = parsed.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "skip_fields = ['PARENT_SEQ', 'INDICATOR_SEQ',\n",
    "               'DESIRED_CHANGE', 'DECIMAL_PLACES']\n",
    "\n",
    "for elt in root.INDICATOR:\n",
    "    el_data = {}\n",
    "    for child in elt.getchildren():\n",
    "        if child.tag in skip_fields:\n",
    "            continue\n",
    "        el_data[child.tag] = child.pyval\n",
    "    data.append(el_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = DataFrame(data)\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary data formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('ch06/ex1.csv')\n",
    "frame\n",
    "frame.to_pickle('ch06/frame_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('ch06/frame_pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore('mydata.h5')\n",
    "store['obj1'] = frame\n",
    "store['obj1_col'] = frame['a']\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store['obj1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.close()\n",
    "os.remove('mydata.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with HTML and Web APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://api.github.com/repos/pydata/pandas/milestones/28/labels'\n",
    "resp = requests.get(url)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_labels = DataFrame(data)\n",
    "issue_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3      # sqlite3 - \n",
    "\n",
    "# DDL 작성\n",
    "query = \"\"\" \n",
    "CREATE TABLE test\n",
    "(a VARCHAR(20), b VARCHAR(20),\n",
    " c REAL,        d INTEGER\n",
    ");\"\"\"\n",
    "\n",
    "con = sqlite3.connect(':memory:')\n",
    "con.execute(query)\n",
    "con.commit()             # 기록을 하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Atlanta', 'Georgia', 1.25, 6),\n",
    "        ('Tallahassee', 'Florida', 2.6, 3),\n",
    "        ('Sacramento', 'California', 1.7, 5)]\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"      \n",
    "# 문장은 1개지만 데이터는 3건이 들어가있음.\n",
    "\n",
    "con.executemany(stmt, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = con.execute('select * from test')\n",
    "rows = cursor.fetchall()    # fetchall 다 가져와라.\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rows, columns=list(zip(*cursor.description))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.io.sql as sql\n",
    "sql.read_sql('select * from test', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas with Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install sqlalchemy\n",
    "conda install cx_oracle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import cx_Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('oracle://scott:tiger@127.0.0.1:1521/XE')\n",
    "#engine = create_engine('oracle://scott:tiger@localhost:1521/XE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with engine.connect() as conn, conn.begin():\n",
    "    data = pd.read_sql_table('emp', conn)\n",
    "    \n",
    "    # 안된다면... 스콧유저 만들고, scott.sql. 파일 불러오고, \n",
    "    # scott 처음에 비밀번호는 TIGER 대문자로 되어있어서 소문자로 바꿔주는 작업을 해준다.\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>empno</th>\n",
       "      <th>ename</th>\n",
       "      <th>job</th>\n",
       "      <th>mgr</th>\n",
       "      <th>hiredate</th>\n",
       "      <th>sal</th>\n",
       "      <th>comm</th>\n",
       "      <th>deptno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7369</td>\n",
       "      <td>SMITH</td>\n",
       "      <td>CLERK</td>\n",
       "      <td>7902.0</td>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7499</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>SALESMAN</td>\n",
       "      <td>7698.0</td>\n",
       "      <td>1981-02-20</td>\n",
       "      <td>1600</td>\n",
       "      <td>300.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7521</td>\n",
       "      <td>WARD</td>\n",
       "      <td>SALESMAN</td>\n",
       "      <td>7698.0</td>\n",
       "      <td>1981-02-22</td>\n",
       "      <td>1250</td>\n",
       "      <td>500.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7566</td>\n",
       "      <td>JONES</td>\n",
       "      <td>MANAGER</td>\n",
       "      <td>7839.0</td>\n",
       "      <td>1981-04-02</td>\n",
       "      <td>2975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7654</td>\n",
       "      <td>MARTIN</td>\n",
       "      <td>SALESMAN</td>\n",
       "      <td>7698.0</td>\n",
       "      <td>1981-09-28</td>\n",
       "      <td>1250</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7698</td>\n",
       "      <td>BLAKE</td>\n",
       "      <td>MANAGER</td>\n",
       "      <td>7839.0</td>\n",
       "      <td>1981-05-01</td>\n",
       "      <td>2850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7782</td>\n",
       "      <td>CLARK</td>\n",
       "      <td>MANAGER</td>\n",
       "      <td>7839.0</td>\n",
       "      <td>1981-06-09</td>\n",
       "      <td>2450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7839</td>\n",
       "      <td>KING</td>\n",
       "      <td>PRESIDENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981-11-17</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7844</td>\n",
       "      <td>TURNER</td>\n",
       "      <td>SALESMAN</td>\n",
       "      <td>7698.0</td>\n",
       "      <td>1981-09-08</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7900</td>\n",
       "      <td>JAMES</td>\n",
       "      <td>CLERK</td>\n",
       "      <td>7698.0</td>\n",
       "      <td>1981-12-03</td>\n",
       "      <td>950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7902</td>\n",
       "      <td>FORD</td>\n",
       "      <td>ANALYST</td>\n",
       "      <td>7566.0</td>\n",
       "      <td>1981-12-03</td>\n",
       "      <td>3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7934</td>\n",
       "      <td>MILLER</td>\n",
       "      <td>CLERK</td>\n",
       "      <td>7782.0</td>\n",
       "      <td>1982-01-23</td>\n",
       "      <td>1300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    empno   ename        job     mgr   hiredate   sal    comm  deptno\n",
       "0    7369   SMITH      CLERK  7902.0 1980-12-17   800     NaN      20\n",
       "1    7499   ALLEN   SALESMAN  7698.0 1981-02-20  1600   300.0      30\n",
       "2    7521    WARD   SALESMAN  7698.0 1981-02-22  1250   500.0      30\n",
       "3    7566   JONES    MANAGER  7839.0 1981-04-02  2975     NaN      20\n",
       "4    7654  MARTIN   SALESMAN  7698.0 1981-09-28  1250  1400.0      30\n",
       "5    7698   BLAKE    MANAGER  7839.0 1981-05-01  2850     NaN      30\n",
       "6    7782   CLARK    MANAGER  7839.0 1981-06-09  2450     NaN      10\n",
       "7    7839    KING  PRESIDENT     NaN 1981-11-17  5000     NaN      10\n",
       "8    7844  TURNER   SALESMAN  7698.0 1981-09-08  1500     0.0      30\n",
       "9    7900   JAMES      CLERK  7698.0 1981-12-03   950     NaN      30\n",
       "10   7902    FORD    ANALYST  7566.0 1981-12-03  3000     NaN      20\n",
       "11   7934  MILLER      CLERK  7782.0 1982-01-23  1300     NaN      10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
